= midScale new SQL repository experiments

As a non-involved developer you may ignore this directory.
It is not part of the current midPoint build.

See also https://docs.evolveum.com/midpoint/midscale/design/repository-design/[midScale Repository Design] document.

== Notes

* Directory `sql` contains various init scripts and experiments.
Some of these will be moved to `config/sql` when proven worthy.
* Create DB schema script (WIP): link:sql/pgnew-repo.sql[]
* Useful inserts, selects, etc.: link:sql/pgnew-experiments.sql[]

== PostgreSQL table inheritance

https://www.postgresql.org/docs/current/ddl-inherit.html[Table inheritance] is a nice mechanism
that allows creating table hierarchies so we see all objects in one table and various subtypes in
inherited tables.
*It is also an implicit method for partitioning*, at least from the perspective of the parent table(s).

* We need "abstract" tables like `m_object`.
Alternative would be a view with `SELECT ... UNION` and common columns have to be repeated in DDL.
Ideally we don't want to insert into abstract tables, we can use `check (false) no inherit` for this.
"Check false" always fails, but this is not inherited by sub-tables.
Updates of common columns or deletes on abstract tables still work with expected results
(not possible with view without additional measures like triggers).

* PKs, FKs and most of other constraints must be declared on each sub-table.
Only check and not-null constraints are inherited, unless `no inherit` is declared.
See https://www.postgresql.org/docs/current/ddl-inherit.html#DDL-INHERIT-CAVEATS[inheritance caveats].

* To assure globally unique PKs we have to use triggers on sub-tables or separate OID-pool table.
We chose the separate table solution after
See http://blog.ioguix.net/postgresql/2015/02/05/Partitionning-and-constraints-part-1.html[this post]
for more - especially the solution towards the end with advisory locks.
The part with the support for other types is also handy, because UUID is bigger than bigint for lock.

* UUID is far from the first recommendation for a PK, but it's impractical to use anything else for midPoint.
Even with additional serial PK the objects are searched by their OID, so it would have to be indexed
and its uniqueness assured and then it can just be PK directly.
Smaller PK could be beneficial only as FK from other tables, e.g. instead of `targetRef_oid` for associations.
This could still mean that we need to follow the FK to resolve it to OID which we use in application.

* We want to generate OID in the database, so `DEFAULT gen_random_uuid()` is used for `OID`
column directly in the master table `m_object`.

* To assure unique OIDs we will use separate `m_object_oid` table.
Triggers for insert and delete will assure the consistency between this and `m_object` hierarchy.
For inserts we have to generate OID if its not provided or use the one that is - in both cases
the new OID is inserted into `m_object_oid`.
Updates of OID are forbidden which is also guarded by a trigger, otherwise it would be able to
change OID to already existing OID from another table (PK does not allow it for the same table).

* Can we partition inherited table? Like `m_shadow`.
*No, this is not possible.*
Options:
** Using "application managed partitioning" with inheritance as needed.
(I prefer this, it is more cumbersome, but possibly more flexible.)
** Shadow would not be part of `m_object` hierarchy.

* Foreign key can't be used against `m_object.oid` because it does not enforce index (by itself).
Perhaps we want to introduce `m_object_oid` table that would own the unique pool of OIDs and could
be used for referencing FKs.
Referencing only some types of objects (e.g. just focuses) is probably mission impossible.


* TODO: membership searches on abstract tables (e.g. focus), EXPLAIN, performance?

* TODO: logging of all statements for experiments?
https://www.postgresql.org/docs/current/runtime-config-logging.html
https://stackoverflow.com/questions/722221/how-to-log-postgresql-queries

* TODO: tablespaces?

* The default `public` schema is used for all midpoint objects, that's OK.

== Pagination

Various types of pagination are summed up in https://www.citusdata.com/blog/2016/03/30/five-ways-to-paginate/[this article].

For *pagination in the GUI* `OFFSET`/`LIMIT` seems to be the acceptable despite the performance
degradation with big values of `OFFSET`.
The reason is that GUI requires random access and first pages are accessed more than later/last pages.
Also, any inconsistency (suddenly added entry) is easy to explain and user probably knows what is happening.

For long term processes that need to process many items we use *keyset pagination*, e.g. using last
ID from current page to define the next page without any `OFFSET`, only using `LIMIT`.
This is very efficient and natural, too.
While this may skip some items that are added after we processed the page (and at the same time
process other items added later that appear on later pages) it is more or less deterministic.
We can also avoid processing "future" items with `WHERE` clause using creation timestamp
(or current maximal ID, if sequential) at the processing start time.

Following techniques are generally not usable for us:

* *TID Scan* and *Keyset with Estimated Bookmarks* does not support `WHERE` clauses.
* *Cursor* pagination causes high client-server coupling and is state-full.
We don't want to hold the cursor for operations that can take longer and need transactions.

== Performance

Tested on VirtualBox, 2 GB RAM, 60+ GB disk.

Insert performance measurements:

----
INSERT INTO m_user (name_norm, name_orig, version)
  VALUES ('user-' || LPAD(r::text, 10, '0'), 'user-' || LPAD(r::text, 10, '0'), 1);
----

Both name columns are indexed, `name_norm` is also unique.
Loop is used to INSERT the rows, which is slower than `INSERT from SELECT` with `generate_series`,
but closer to real scenario that uses separate statements (although there are no round-trips here).

Effect of the number of inherited tables on INSERT performance.
`VACUUM` was used after massive deletes, otherwise the times for 10M were similar to 40M.
This should not be problematic when separate `m_object_oid` table is used now.

|===
| Inherited{nbsp}tables / Existing rows | 4 | 50 | 100

| 0 | 6s | 6s | 6s
| 1M | 6s | - | 6s
| 10M | 29/14/14s | - | 28/12/27s
| 40M | 74/70/72s | 70s | 70s
|===

Conclusion - as there is no check against `m_object` there is no negative impact of the hierarchy on the performance.

Table sizes after x inserts (index means PK index):

|===
| Inserted rows total | User table/index size | OID table/index size | DB size

| 0 | | |
| 1M | 96/30 MB | 42/30 MB | 266 MB
| 10M | 965/446 MB | 422/446 MB | 2888 MB
| 40M | 3858/1721 MB | 1689/1721 MB | 11 GB
|===

With user names formatted like `user-0000000001` both name indexes had 1269 MB at 40M rows.


== Performance of searching for unused OIDs

If delete is not guarded by trigger `m_object_oid` can have unused OIDs.
It's crucial to use the right select/delete construction to find/delete them.
With 26M rows naive approach with `NOT IN` to delete 200k unused OIDs took over 1h without finishing.
Following output shows the plan for `NOT IN`, `LEFT JOIN` and `NOT EXISTS`.
Latter two use `Parallel Hash Anti Join` which is good, `NOT IN` uses `Parallel Seq Scan` which is not.
`NOT EXISTS` is practical for `DELETE`/`UPDATE` and perfectly valid to use.
The previous problem (deleting 200k unused OIDs from 26M total) was solved in around 150s.

----
EXPLAIN -- (ANALYZE, BUFFERS, FORMAT TEXT) with analyze it's super slow, EXPLAIN is enough here
select * FROM m_object_oid WHERE OID NOT IN (SELECT oid from m_object);

Gather  (cost=1000.00..5431677337728.88 rows=13150078 width=16)
  Workers Planned: 2
  ->  Parallel Seq Scan on m_object_oid  (cost=0.00..5431676021721.08 rows=5479199 width=16)
        Filter: (NOT (SubPlan 1))
        SubPlan 1
          ->  Materialize  (cost=0.00..925576.32 rows=26300117 width=16)
                ->  Append  (cost=0.00..665656.73 rows=26300117 width=16)
                      ->  Seq Scan on m_object m_object_1  (cost=0.00..0.00 rows=1 width=16)
                      ->  Seq Scan on m_resource m_object_2  (cost=0.00..10.10 rows=10 width=16)
                      ->  Seq Scan on m_focus m_object_3  (cost=0.00..0.00 rows=1 width=16)
                      ->  Seq Scan on m_shadow m_object_4  (cost=0.00..10.10 rows=10 width=16)
                      ->  Seq Scan on m_user m_object_5  (cost=0.00..534135.95 rows=26300095 width=16)
JIT:
  Functions: 14
"  Options: Inlining true, Optimization true, Expressions true, Deforming true"

EXPLAIN select count(oo.oid) FROM m_object_oid oo
left join m_object o on o.oid = oo.oid
WHERE o.oid is null;

Gather  (cost=627018.54..1217367.23 rows=38 width=16)
  Workers Planned: 2
  ->  Parallel Hash Anti Join  (cost=626018.54..1216363.43 rows=16 width=16)
        Hash Cond: (oo.oid = o.oid)
        ->  Parallel Seq Scan on m_object_oid oo  (cost=0.00..251746.98 rows=10958398 width=16)
        ->  Parallel Hash  (cost=435530.76..435530.76 rows=10958383 width=16)
              ->  Parallel Append  (cost=0.00..435530.76 rows=10958383 width=16)
                    ->  Seq Scan on m_object o_1  (cost=0.00..0.00 rows=1 width=16)
                    ->  Seq Scan on m_focus o_3  (cost=0.00..0.00 rows=1 width=16)
                    ->  Parallel Seq Scan on m_user o_5  (cost=0.00..380718.73 rows=10958373 width=16)
                    ->  Parallel Seq Scan on m_resource o_2  (cost=0.00..10.06 rows=6 width=16)
                    ->  Parallel Seq Scan on m_shadow o_4  (cost=0.00..10.06 rows=6 width=16)
JIT:
  Functions: 18
"  Options: Inlining true, Optimization true, Expressions true, Deforming true"

EXPLAIN
delete FROM m_object_oid oo
where not exists (select * from m_object o where o.oid = oo.oid);

Gather  (cost=627018.54..1217367.23 rows=38 width=16)
  Workers Planned: 2
  ->  Parallel Hash Anti Join  (cost=626018.54..1216363.43 rows=16 width=16)
        Hash Cond: (oo.oid = o.oid)
        ->  Parallel Seq Scan on m_object_oid oo  (cost=0.00..251746.98 rows=10958398 width=16)
        ->  Parallel Hash  (cost=435530.76..435530.76 rows=10958383 width=16)
              ->  Parallel Append  (cost=0.00..435530.76 rows=10958383 width=16)
                    ->  Seq Scan on m_object o_1  (cost=0.00..0.00 rows=1 width=16)
                    ->  Seq Scan on m_focus o_3  (cost=0.00..0.00 rows=1 width=16)
                    ->  Parallel Seq Scan on m_user o_5  (cost=0.00..380718.73 rows=10958373 width=16)
                    ->  Parallel Seq Scan on m_resource o_2  (cost=0.00..10.06 rows=6 width=16)
                    ->  Parallel Seq Scan on m_shadow o_4  (cost=0.00..10.06 rows=6 width=16)
JIT:
  Functions: 18
"  Options: Inlining true, Optimization true, Expressions true, Deforming true"
----